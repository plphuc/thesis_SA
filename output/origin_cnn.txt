nohup: ignoring input
Bert Tokenizer Loaded...
Data loading complete
Number of training examples: 441000
Number of validation examples: 189000
Number of test examples: 270000
defaultdict(None, {'0.0': 0, '1.0': 1, '2.0': 2})
Device in use:  cuda
Epoch: 01 | Epoch Time: 41m 10s
	Train Loss: 0.447 | Train Acc: 81.89%
	 Val. Loss: 0.368 |  Val. Acc: 85.45%
tensor([0.8868, 0.7513, 0.9077, 0.8441])
tensor([[56116.,  6075.,   901.],
        [ 6745., 47982.,  8416.],
        [  914.,  4462., 57389.]], dtype=torch.float64)
Epoch: 02 | Epoch Time: 40m 31s
	Train Loss: 0.404 | Train Acc: 83.93%
	 Val. Loss: 0.362 |  Val. Acc: 85.78%
tensor([0.8820, 0.7703, 0.9098, 0.8486])
tensor([[55844.,  6389.,   859.],
        [ 6259., 49015.,  7869.],
        [  765.,  4746., 57254.]], dtype=torch.float64)
Epoch: 03 | Epoch Time: 41m 13s
	Train Loss: 0.393 | Train Acc: 84.39%
	 Val. Loss: 0.362 |  Val. Acc: 85.60%
tensor([0.8386, 0.8539, 0.8569, 0.8490])
tensor([[53085.,  9405.,   602.],
        [ 4349., 54331.,  4463.],
        [  580.,  7833., 54352.]], dtype=torch.float64)
Epoch: 04 | Epoch Time: 40m 36s
	Train Loss: 0.387 | Train Acc: 84.73%
	 Val. Loss: 0.395 |  Val. Acc: 84.50%
tensor([0.8395, 0.7290, 0.9476, 0.8335])
tensor([[53140.,  8122.,  1830.],
        [ 4576., 46794., 11773.],
        [  455.,  2540., 59770.]], dtype=torch.float64)
Epoch: 05 | Epoch Time: 41m 20s
	Train Loss: 0.383 | Train Acc: 84.85%
	 Val. Loss: 0.352 |  Val. Acc: 86.14%
tensor([0.8797, 0.7916, 0.8989, 0.8528])
tensor([[55747.,  6673.,   672.],
        [ 6332., 50362.,  6449.],
        [  850.,  5228., 56687.]], dtype=torch.float64)
Epoch: 06 | Epoch Time: 40m 34s
	Train Loss: 0.379 | Train Acc: 85.08%
	 Val. Loss: 0.358 |  Val. Acc: 85.94%
tensor([0.8719, 0.7692, 0.9220, 0.8499])
tensor([[55205.,  6967.,   920.],
        [ 5851., 49054.,  8238.],
        [  610.,  3990., 58165.]], dtype=torch.float64)
Epoch: 07 | Epoch Time: 41m 10s
	Train Loss: 0.377 | Train Acc: 85.14%
	 Val. Loss: 0.354 |  Val. Acc: 86.13%
tensor([0.8664, 0.8118, 0.8869, 0.8531])
tensor([[54800.,  7589.,   703.],
        [ 5366., 51807.,  5970.],
        [  687.,  5901., 56177.]], dtype=torch.float64)
Epoch: 08 | Epoch Time: 40m 32s
	Train Loss: 0.376 | Train Acc: 85.22%
	 Val. Loss: 0.353 |  Val. Acc: 86.24%
tensor([0.8919, 0.7645, 0.9169, 0.8527])
tensor([[56435.,  5795.,   862.],
        [ 6579., 48751.,  7813.],
        [  754.,  4211., 57800.]], dtype=torch.float64)
Epoch: 09 | Epoch Time: 40m 57s
	Train Loss: 0.374 | Train Acc: 85.25%
	 Val. Loss: 0.361 |  Val. Acc: 85.76%
tensor([0.8361, 0.8198, 0.9045, 0.8499])
tensor([[52927.,  9343.,   822.],
        [ 4293., 52179.,  6671.],
        [  556.,  5244., 56965.]], dtype=torch.float64)
Epoch: 10 | Epoch Time: 40m 53s
	Train Loss: 0.372 | Train Acc: 85.37%
	 Val. Loss: 0.358 |  Val. Acc: 85.92%
tensor([0.8388, 0.8242, 0.8987, 0.8514])
tensor([[53198.,  9279.,   615.],
        [ 4439., 52437.,  6267.],
        [  575.,  5437., 56753.]], dtype=torch.float64)
Epoch: 11 | Epoch Time: 41m 31s
	Train Loss: 0.371 | Train Acc: 85.46%
	 Val. Loss: 0.355 |  Val. Acc: 86.10%
tensor([0.8566, 0.8005, 0.9100, 0.8526])
tensor([[54234.,  8030.,   828.],
        [ 5048., 51041.,  7054.],
        [  568.,  4743., 57454.]], dtype=torch.float64)
Epoch: 12 | Epoch Time: 43m 49s
	Train Loss: 0.368 | Train Acc: 85.51%
	 Val. Loss: 0.350 |  Val. Acc: 86.47%
tensor([0.8975, 0.7813, 0.8997, 0.8556])
tensor([[56784.,  5608.,   700.],
        [ 6991., 49823.,  6329.],
        [  890.,  5062., 56813.]], dtype=torch.float64)
Epoch: 13 | Epoch Time: 28m 44s
	Train Loss: 0.368 | Train Acc: 85.52%
	 Val. Loss: 0.359 |  Val. Acc: 86.01%
tensor([0.8885, 0.7633, 0.9120, 0.8502])
tensor([[56211.,  6010.,   871.],
        [ 6760., 48761.,  7622.],
        [  832.,  4356., 57577.]], dtype=torch.float64)
Epoch: 14 | Epoch Time: 19m 29s
	Train Loss: 0.368 | Train Acc: 85.56%
	 Val. Loss: 0.356 |  Val. Acc: 86.08%
tensor([0.8703, 0.7947, 0.9011, 0.8521])
tensor([[55145.,  7165.,   782.],
        [ 5802., 50621.,  6720.],
        [  688.,  5165., 56912.]], dtype=torch.float64)
Epoch: 15 | Epoch Time: 19m 30s
	Train Loss: 0.366 | Train Acc: 85.68%
	 Val. Loss: 0.357 |  Val. Acc: 86.10%
tensor([0.8894, 0.8064, 0.8731, 0.8530])
tensor([[56298.,  6279.,   515.],
        [ 6710., 51311.,  5122.],
        [  934.,  6712., 55119.]], dtype=torch.float64)
Epoch: 16 | Epoch Time: 25m 24s
	Train Loss: 0.367 | Train Acc: 85.58%
	 Val. Loss: 0.358 |  Val. Acc: 85.89%
tensor([0.8718, 0.8389, 0.8510, 0.8519])
tensor([[55195.,  7451.,   446.],
        [ 5670., 53348.,  4125.],
        [  790.,  8203., 53772.]], dtype=torch.float64)
Epoch: 17 | Epoch Time: 30m 1s
	Train Loss: 0.364 | Train Acc: 85.66%
	 Val. Loss: 0.351 |  Val. Acc: 86.39%
tensor([0.8836, 0.7973, 0.8964, 0.8555])
tensor([[55871.,  6557.,   664.],
        [ 6211., 50825.,  6107.],
        [  722.,  5463., 56580.]], dtype=torch.float64)
Epoch: 18 | Epoch Time: 19m 44s
	Train Loss: 0.364 | Train Acc: 85.75%
	 Val. Loss: 0.355 |  Val. Acc: 86.09%
tensor([0.8584, 0.8360, 0.8732, 0.8537])
tensor([[54339.,  8193.,   560.],
        [ 5002., 53173.,  4968.],
        [  730.,  6831., 55204.]], dtype=torch.float64)
Epoch: 19 | Epoch Time: 19m 27s
	Train Loss: 0.362 | Train Acc: 85.76%
	 Val. Loss: 0.359 |  Val. Acc: 86.12%
tensor([0.8792, 0.7955, 0.8938, 0.8527])
tensor([[55714.,  6713.,   665.],
        [ 6337., 50618.,  6188.],
        [  886.,  5454., 56425.]], dtype=torch.float64)
Epoch: 20 | Epoch Time: 19m 28s
	Train Loss: 0.363 | Train Acc: 85.69%
	 Val. Loss: 0.357 |  Val. Acc: 85.96%
tensor([0.8840, 0.8236, 0.8577, 0.8522])
tensor([[55933.,  6737.,   422.],
        [ 6340., 52350.,  4453.],
        [  945.,  7642., 54178.]], dtype=torch.float64)
	 Val. Loss: 0.350 |  Val. Acc: 86.42%
tensor([0.8986, 0.7772, 0.9001, 0.8548])
