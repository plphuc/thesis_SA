nohup: ignoring input
XLM Roberta Tokenizer Loaded...
Data loading complete
Number of training examples: 441000
Number of validation examples: 189000
Number of test examples: 270000
defaultdict(None, {'0.0': 0, '1.0': 1, '2.0': 2})
Device in use:  cuda
Epoch: 01 | Epoch Time: 34m 33s
	Train Loss: 0.606 | Train Acc: 73.79%
	 Val. Loss: 0.456 |  Val. Acc: 82.08%
tensor([0.8686, 0.6639, 0.9169, 0.8072])
tensor([[55048.,  6170.,  1874.],
        [ 7971., 42236., 12936.],
        [ 1247.,  3675., 57843.]], dtype=torch.float64)
Epoch: 02 | Epoch Time: 34m 48s
	Train Loss: 0.478 | Train Acc: 80.33%
	 Val. Loss: 0.413 |  Val. Acc: 83.83%
tensor([0.9207, 0.6908, 0.8858, 0.8257])
tensor([[58177.,  4084.,   831.],
        [10639., 44199.,  8305.],
        [ 1879.,  4815., 56071.]], dtype=torch.float64)
Epoch: 03 | Epoch Time: 34m 39s
	Train Loss: 0.446 | Train Acc: 81.73%
	 Val. Loss: 0.425 |  Val. Acc: 83.92%
tensor([0.8570, 0.8170, 0.8161, 0.8298])
tensor([[54157.,  8250.,   685.],
        [ 5993., 52202.,  4948.],
        [ 1349.,  9153., 52263.]], dtype=torch.float64)
Epoch: 04 | Epoch Time: 34m 36s
	Train Loss: 0.426 | Train Acc: 82.62%
	 Val. Loss: 0.412 |  Val. Acc: 84.35%
tensor([0.9063, 0.6854, 0.9246, 0.8303])
tensor([[57293.,  4540.,  1259.],
        [ 8553., 43868., 10722.],
        [ 1287.,  3209., 58269.]], dtype=torch.float64)
Epoch: 05 | Epoch Time: 34m 41s
	Train Loss: 0.413 | Train Acc: 83.25%
	 Val. Loss: 0.416 |  Val. Acc: 84.80%
tensor([0.9047, 0.7483, 0.8729, 0.8373])
tensor([[57108.,  5229.,   755.],
        [ 8176., 47916.,  7051.],
        [ 1615.,  5901., 55249.]], dtype=torch.float64)
Epoch: 06 | Epoch Time: 34m 27s
	Train Loss: 0.403 | Train Acc: 83.67%
	 Val. Loss: 0.374 |  Val. Acc: 85.50%
tensor([0.9091, 0.7467, 0.8879, 0.8443])
tensor([[57508.,  4770.,   814.],
        [ 8339., 47737.,  7067.],
        [ 1373.,  5040., 56352.]], dtype=torch.float64)
Epoch: 07 | Epoch Time: 34m 32s
	Train Loss: 0.396 | Train Acc: 83.99%
	 Val. Loss: 0.392 |  Val. Acc: 85.42%
tensor([0.9103, 0.7679, 0.8610, 0.8439])
tensor([[57538.,  4899.,   655.],
        [ 8179., 49081.,  5883.],
        [ 1522.,  6411., 54832.]], dtype=torch.float64)
Epoch: 08 | Epoch Time: 34m 28s
	Train Loss: 0.388 | Train Acc: 84.33%
	 Val. Loss: 0.412 |  Val. Acc: 85.17%
tensor([0.8688, 0.7448, 0.9241, 0.8410])
tensor([[54933.,  6609.,  1550.],
        [ 5871., 47676.,  9596.],
        [  665.,  3747., 58353.]], dtype=torch.float64)
Epoch: 09 | Epoch Time: 34m 38s
	Train Loss: 0.383 | Train Acc: 84.50%
	 Val. Loss: 0.397 |  Val. Acc: 85.32%
tensor([0.8720, 0.7568, 0.9120, 0.8430])
tensor([[55194.,  6532.,  1366.],
        [ 6194., 48387.,  8562.],
        [  737.,  4354., 57674.]], dtype=torch.float64)
Epoch: 10 | Epoch Time: 31m 45s
	Train Loss: 0.378 | Train Acc: 84.78%
	 Val. Loss: 0.395 |  Val. Acc: 85.58%
tensor([0.8950, 0.7973, 0.8555, 0.8470])
tensor([[56546.,  5928.,   618.],
        [ 7289., 50912.,  4942.],
        [ 1246.,  7217., 54302.]], dtype=torch.float64)
Epoch: 11 | Epoch Time: 28m 47s
	Train Loss: 0.374 | Train Acc: 84.89%
	 Val. Loss: 0.392 |  Val. Acc: 85.95%
tensor([0.8916, 0.7831, 0.8830, 0.8502])
tensor([[56372.,  5758.,   962.],
        [ 6908., 50050.,  6185.],
        [  962.,  5780., 56023.]], dtype=torch.float64)
Epoch: 12 | Epoch Time: 28m 57s
	Train Loss: 0.372 | Train Acc: 85.00%
	 Val. Loss: 0.395 |  Val. Acc: 85.71%
tensor([0.8967, 0.7638, 0.8902, 0.8469])
tensor([[56665.,  5293.,  1134.],
        [ 7516., 48913.,  6714.],
        [  952.,  5388., 56425.]], dtype=torch.float64)
Epoch: 13 | Epoch Time: 28m 39s
	Train Loss: 0.368 | Train Acc: 85.17%
	 Val. Loss: 0.400 |  Val. Acc: 85.37%
tensor([0.9338, 0.7124, 0.9005, 0.8420])
tensor([[58995.,  3292.,   805.],
        [10415., 45585.,  7143.],
        [ 1503.,  4493., 56769.]], dtype=torch.float64)
Epoch: 14 | Epoch Time: 28m 53s
	Train Loss: 0.366 | Train Acc: 85.29%
	 Val. Loss: 0.387 |  Val. Acc: 85.82%
tensor([0.9081, 0.7318, 0.9182, 0.8471])
tensor([[57426.,  4578.,  1088.],
        [ 7898., 46835.,  8410.],
        [ 1065.,  3758., 57942.]], dtype=torch.float64)
Epoch: 15 | Epoch Time: 34m 6s
	Train Loss: 0.363 | Train Acc: 85.41%
	 Val. Loss: 0.415 |  Val. Acc: 85.45%
tensor([0.9137, 0.7419, 0.8934, 0.8441])
tensor([[57749.,  4340.,  1003.],
        [ 8789., 47364.,  6990.],
        [ 1139.,  5225., 56401.]], dtype=torch.float64)
Epoch: 16 | Epoch Time: 34m 18s
	Train Loss: 0.361 | Train Acc: 85.52%
	 Val. Loss: 0.398 |  Val. Acc: 85.67%
tensor([0.9149, 0.7440, 0.8949, 0.8462])
tensor([[57808.,  4323.,   961.],
        [ 8744., 47586.,  6813.],
        [ 1266.,  4963., 56536.]], dtype=torch.float64)
Epoch: 17 | Epoch Time: 34m 12s
	Train Loss: 0.358 | Train Acc: 85.59%
	 Val. Loss: 0.408 |  Val. Acc: 85.76%
tensor([0.9030, 0.7673, 0.8837, 0.8477])
tensor([[57082.,  5039.,   971.],
        [ 7668., 49069.,  6406.],
        [ 1000.,  5829., 55936.]], dtype=torch.float64)
Epoch: 18 | Epoch Time: 34m 20s
	Train Loss: 0.357 | Train Acc: 85.71%
	 Val. Loss: 0.386 |  Val. Acc: 85.91%
tensor([0.8649, 0.8021, 0.8919, 0.8506])
tensor([[54657.,  7296.,  1139.],
        [ 5541., 51259.,  6343.],
        [  744.,  5564., 56457.]], dtype=torch.float64)
Epoch: 19 | Epoch Time: 34m 11s
	Train Loss: 0.354 | Train Acc: 85.75%
	 Val. Loss: 0.382 |  Val. Acc: 86.21%
tensor([0.9014, 0.7855, 0.8837, 0.8534])
tensor([[57003.,  5330.,   759.],
        [ 7383., 50107.,  5653.],
        [ 1143.,  5797., 55825.]], dtype=torch.float64)
Epoch: 20 | Epoch Time: 34m 19s
	Train Loss: 0.354 | Train Acc: 85.73%
	 Val. Loss: 0.396 |  Val. Acc: 85.84%
tensor([0.9222, 0.7582, 0.8733, 0.8482])
tensor([[58272.,  4212.,   608.],
        [ 9055., 48510.,  5578.],
        [ 1436.,  5854., 55475.]], dtype=torch.float64)
	 Val. Loss: 0.380 |  Val. Acc: 86.30%
tensor([0.9044, 0.7826, 0.8853, 0.8539])
