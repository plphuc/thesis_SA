nohup: ignoring input
Bert Tokenizer Loaded...
Data loading complete
Number of training examples: 441000
Number of validation examples: 189000
Number of test examples: 270000
defaultdict(None, {'0.0': 0, '1.0': 1, '2.0': 2})
Device in use:  cuda
Epoch: 01 | Epoch Time: 11m 23s
	Train Loss: 0.433 | Train Acc: 82.21%
	 Val. Loss: 0.399 |  Val. Acc: 84.07%
tensor([0.9027, 0.6846, 0.9157, 0.8275])
tensor([[57132.,  4592.,  1368.],
        [ 9362., 43797.,  9984.],
        [  972.,  3837., 57956.]], dtype=torch.float64)
Epoch: 02 | Epoch Time: 25m 14s
	Train Loss: 0.365 | Train Acc: 85.32%
	 Val. Loss: 0.385 |  Val. Acc: 84.72%
tensor([0.8864, 0.7267, 0.9147, 0.8359])
tensor([[56024.,  6010.,  1058.],
        [ 7528., 46464.,  9151.],
        [ 1021.,  4114., 57630.]], dtype=torch.float64)
Epoch: 03 | Epoch Time: 26m 29s
	Train Loss: 0.344 | Train Acc: 86.27%
	 Val. Loss: 0.366 |  Val. Acc: 85.63%
tensor([0.8928, 0.8062, 0.8504, 0.8477])
tensor([[56455.,  6142.,   495.],
        [ 7131., 51465.,  4547.],
        [ 1104.,  7757., 53904.]], dtype=torch.float64)
Epoch: 04 | Epoch Time: 27m 9s
	Train Loss: 0.331 | Train Acc: 86.87%
	 Val. Loss: 0.355 |  Val. Acc: 86.05%
tensor([0.9085, 0.7592, 0.9031, 0.8510])
tensor([[57380.,  4887.,   825.],
        [ 7875., 48478.,  6790.],
        [ 1072.,  4927., 56766.]], dtype=torch.float64)
Epoch: 05 | Epoch Time: 26m 25s
	Train Loss: 0.321 | Train Acc: 87.23%
	 Val. Loss: 0.342 |  Val. Acc: 86.58%
tensor([0.8994, 0.7791, 0.9060, 0.8568])
tensor([[56834.,  5526.,   732.],
        [ 6737., 49726.,  6680.],
        [  931.,  4770., 57064.]], dtype=torch.float64)
Epoch: 06 | Epoch Time: 26m 34s
	Train Loss: 0.316 | Train Acc: 87.48%
	 Val. Loss: 0.353 |  Val. Acc: 86.42%
tensor([0.8636, 0.8113, 0.9026, 0.8563])
tensor([[54622.,  7741.,   729.],
        [ 5112., 51735.,  6296.],
        [  644.,  5159., 56962.]], dtype=torch.float64)
Epoch: 07 | Epoch Time: 27m 8s
	Train Loss: 0.310 | Train Acc: 87.76%
	 Val. Loss: 0.343 |  Val. Acc: 86.76%
tensor([0.9046, 0.7877, 0.8927, 0.8588])
tensor([[57168.,  5350.,   574.],
        [ 6996., 50343.,  5804.],
        [  999.,  5317., 56449.]], dtype=torch.float64)
Epoch: 08 | Epoch Time: 26m 40s
	Train Loss: 0.306 | Train Acc: 87.87%
	 Val. Loss: 0.346 |  Val. Acc: 86.58%
tensor([0.9015, 0.7674, 0.9162, 0.8563])
tensor([[56978.,  5183.,   931.],
        [ 6829., 49031.,  7283.],
        [  833.,  4320., 57612.]], dtype=torch.float64)
Epoch: 09 | Epoch Time: 26m 25s
	Train Loss: 0.302 | Train Acc: 88.10%
	 Val. Loss: 0.345 |  Val. Acc: 86.25%
tensor([0.8643, 0.8159, 0.8978, 0.8553])
tensor([[54642.,  7707.,   743.],
        [ 5001., 51972.,  6170.],
        [  652.,  5727., 56386.]], dtype=torch.float64)
Epoch: 10 | Epoch Time: 27m 9s
	Train Loss: 0.300 | Train Acc: 88.15%
	 Val. Loss: 0.342 |  Val. Acc: 86.36%
tensor([0.8698, 0.8079, 0.8984, 0.8557])
tensor([[54968.,  7485.,   639.],
        [ 5347., 51615.,  6181.],
        [  645.,  5484., 56636.]], dtype=torch.float64)
Epoch: 11 | Epoch Time: 26m 26s
	Train Loss: 0.298 | Train Acc: 88.21%
	 Val. Loss: 0.352 |  Val. Acc: 85.91%
tensor([0.8578, 0.8211, 0.8941, 0.8526])
tensor([[54265.,  7913.,   914.],
        [ 4803., 52203.,  6137.],
        [  518.,  6360., 55887.]], dtype=torch.float64)
Epoch: 12 | Epoch Time: 26m 26s
	Train Loss: 0.294 | Train Acc: 88.40%
	 Val. Loss: 0.334 |  Val. Acc: 86.98%
tensor([0.8872, 0.8081, 0.8991, 0.8617])
tensor([[56104.,  6296.,   692.],
        [ 5861., 51568.,  5714.],
        [  710.,  5350., 56705.]], dtype=torch.float64)
Epoch: 13 | Epoch Time: 27m 9s
	Train Loss: 0.293 | Train Acc: 88.49%
	 Val. Loss: 0.338 |  Val. Acc: 87.03%
tensor([0.8968, 0.7732, 0.9237, 0.8608])
tensor([[56659.,  5570.,   863.],
        [ 6230., 49542.,  7371.],
        [  735.,  3749., 58281.]], dtype=torch.float64)
Epoch: 14 | Epoch Time: 26m 29s
	Train Loss: 0.291 | Train Acc: 88.50%
	 Val. Loss: 0.341 |  Val. Acc: 86.81%
tensor([0.9005, 0.7677, 0.9220, 0.8585])
tensor([[56913.,  5338.,   841.],
        [ 6482., 49106.,  7555.],
        [  841.,  3881., 58043.]], dtype=torch.float64)
Epoch: 15 | Epoch Time: 26m 27s
	Train Loss: 0.290 | Train Acc: 88.55%
	 Val. Loss: 0.335 |  Val. Acc: 86.97%
tensor([0.9085, 0.7842, 0.9018, 0.8608])
tensor([[57424.,  5062.,   606.],
        [ 6977., 50073.,  6093.],
        [ 1012.,  4879., 56874.]], dtype=torch.float64)
Epoch: 16 | Epoch Time: 27m 10s
	Train Loss: 0.288 | Train Acc: 88.63%
	 Val. Loss: 0.336 |  Val. Acc: 86.92%
tensor([0.9070, 0.7883, 0.8998, 0.8606])
tensor([[57268.,  5212.,   612.],
        [ 7084., 50412.,  5647.],
        [ 1017.,  5163., 56585.]], dtype=torch.float64)
Epoch: 17 | Epoch Time: 26m 29s
	Train Loss: 0.287 | Train Acc: 88.64%
	 Val. Loss: 0.332 |  Val. Acc: 87.11%
tensor([0.8781, 0.8086, 0.9146, 0.8634])
tensor([[55520.,  6899.,   673.],
        [ 5228., 51539.,  6376.],
        [  716.,  4473., 57576.]], dtype=torch.float64)
Epoch: 18 | Epoch Time: 27m 36s
	Train Loss: 0.285 | Train Acc: 88.74%
	 Val. Loss: 0.344 |  Val. Acc: 86.65%
tensor([0.8616, 0.8202, 0.9046, 0.8590])
tensor([[54465.,  7755.,   872.],
        [ 4786., 52318.,  6039.],
        [  634.,  5145., 56986.]], dtype=torch.float64)
Epoch: 19 | Epoch Time: 29m 42s
	Train Loss: 0.284 | Train Acc: 88.79%
	 Val. Loss: 0.334 |  Val. Acc: 87.04%
tensor([0.8902, 0.8029, 0.9038, 0.8622])
tensor([[56250.,  6155.,   687.],
        [ 5956., 51297.,  5890.],
        [  873.,  4946., 56946.]], dtype=torch.float64)
Epoch: 20 | Epoch Time: 26m 25s
	Train Loss: 0.284 | Train Acc: 88.78%
	 Val. Loss: 0.339 |  Val. Acc: 86.92%
tensor([0.9231, 0.7831, 0.8870, 0.8606])
tensor([[58329.,  4298.,   465.],
        [ 8109., 50066.,  4968.],
        [ 1199.,  5684., 55882.]], dtype=torch.float64)
	 Val. Loss: 0.329 |  Val. Acc: 87.27%
tensor([0.8829, 0.8084, 0.9141, 0.8647])
