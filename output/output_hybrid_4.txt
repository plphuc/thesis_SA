nohup: ignoring input
Bert Tokenizer Loaded...
Data loading complete
Number of training examples: 441000
Number of validation examples: 189000
Number of test examples: 270000
defaultdict(None, {'0.0': 0, '1.0': 1, '2.0': 2})
Device in use:  cuda
Epoch: 01 | Epoch Time: 64m 6s
	Train Loss: 0.767 | Train Acc: 77.28%
	 Val. Loss: 0.743 |  Val. Acc: 80.39%
tensor([0.8506, 0.5829, 0.9631, 0.7858])
tensor([[53796.,  5394.,  3902.],
        [ 6148., 37484., 19511.],
        [  698.,  1414., 60653.]], dtype=torch.float64)
Epoch: 02 | Epoch Time: 47m 50s
	Train Loss: 0.742 | Train Acc: 79.81%
	 Val. Loss: 0.705 |  Val. Acc: 84.40%
tensor([0.8387, 0.7574, 0.9135, 0.8334])
tensor([[53064.,  8380.,  1648.],
        [ 4928., 48535.,  9680.],
        [  793.,  4071., 57901.]], dtype=torch.float64)
Epoch: 03 | Epoch Time: 54m 3s
	Train Loss: 0.737 | Train Acc: 80.37%
	 Val. Loss: 0.700 |  Val. Acc: 84.96%
tensor([0.8839, 0.7285, 0.9157, 0.8381])
tensor([[55908.,  5870.,  1314.],
        [ 6555., 46653.,  9935.],
        [ 1037.,  3719., 58009.]], dtype=torch.float64)
Epoch: 04 | Epoch Time: 56m 13s
	Train Loss: 0.735 | Train Acc: 80.64%
	 Val. Loss: 0.699 |  Val. Acc: 85.09%
tensor([0.8957, 0.7226, 0.9179, 0.8395])
tensor([[56643.,  5251.,  1198.],
        [ 7511., 46153.,  9479.],
        [ 1130.,  3625., 58010.]], dtype=torch.float64)
Epoch: 05 | Epoch Time: 46m 42s
	Train Loss: 0.734 | Train Acc: 80.81%
	 Val. Loss: 0.699 |  Val. Acc: 85.12%
tensor([0.8498, 0.7754, 0.9077, 0.8413])
tensor([[53871.,  7719.,  1502.],
        [ 5188., 49492.,  8463.],
        [  717.,  4545., 57503.]], dtype=torch.float64)
Epoch: 06 | Epoch Time: 63m 58s
	Train Loss: 0.733 | Train Acc: 80.95%
	 Val. Loss: 0.694 |  Val. Acc: 85.59%
tensor([0.8857, 0.7845, 0.8736, 0.8463])
tensor([[56077.,  5889.,  1126.],
        [ 6805., 50027.,  6311.],
        [  957.,  6161., 55647.]], dtype=torch.float64)
Epoch: 07 | Epoch Time: 46m 42s
	Train Loss: 0.733 | Train Acc: 81.00%
	 Val. Loss: 0.699 |  Val. Acc: 85.13%
tensor([0.8310, 0.8122, 0.8858, 0.8422])
tensor([[52630.,  8933.,  1529.],
        [ 4361., 51866.,  6916.],
        [  624.,  5748., 56393.]], dtype=torch.float64)
Epoch: 08 | Epoch Time: 54m 2s
	Train Loss: 0.733 | Train Acc: 80.99%
	 Val. Loss: 0.698 |  Val. Acc: 85.25%
tensor([0.8690, 0.7557, 0.9112, 0.8420])
tensor([[55030.,  6353.,  1709.],
        [ 5952., 48304.,  8887.],
        [  756.,  4237., 57772.]], dtype=torch.float64)
Epoch: 09 | Epoch Time: 56m 36s
	Train Loss: 0.732 | Train Acc: 81.10%
	 Val. Loss: 0.696 |  Val. Acc: 85.42%
tensor([0.9089, 0.7371, 0.8992, 0.8437])
tensor([[57540.,  4631.,   921.],
        [ 8602., 46966.,  7575.],
        [ 1373.,  4470., 56922.]], dtype=torch.float64)
Epoch: 10 | Epoch Time: 46m 49s
	Train Loss: 0.733 | Train Acc: 81.02%
	 Val. Loss: 0.695 |  Val. Acc: 85.57%
tensor([0.9106, 0.7599, 0.8692, 0.8448])
tensor([[57600.,  4819.,   673.],
        [ 8235., 48596.,  6312.],
        [ 1571.,  5678., 55516.]], dtype=torch.float64)
Epoch: 11 | Epoch Time: 62m 23s
	Train Loss: 0.732 | Train Acc: 81.08%
	 Val. Loss: 0.695 |  Val. Acc: 85.59%
tensor([0.8946, 0.7493, 0.9008, 0.8452])
tensor([[56617.,  5479.,   996.],
        [ 7178., 47938.,  8027.],
        [ 1180.,  4388., 57197.]], dtype=torch.float64)
Epoch: 12 | Epoch Time: 47m 59s
	Train Loss: 0.733 | Train Acc: 81.02%
	 Val. Loss: 0.695 |  Val. Acc: 85.54%
tensor([0.9232, 0.7216, 0.8978, 0.8432])
tensor([[58311.,  3995.,   786.],
        [ 9107., 46331.,  7705.],
        [ 1563.,  4184., 57018.]], dtype=torch.float64)
Epoch: 13 | Epoch Time: 49m 44s
	Train Loss: 0.732 | Train Acc: 81.16%
	 Val. Loss: 0.700 |  Val. Acc: 85.09%
tensor([0.9192, 0.6933, 0.9224, 0.8383])
tensor([[58137.,  3841.,  1114.],
        [ 9036., 44328.,  9779.],
        [ 1299.,  3123., 58343.]], dtype=torch.float64)
Epoch: 14 | Epoch Time: 60m 8s
	Train Loss: 0.733 | Train Acc: 81.06%
	 Val. Loss: 0.706 |  Val. Acc: 84.51%
tensor([0.8013, 0.8495, 0.8635, 0.8374])
tensor([[50721., 11447.,   924.],
        [ 3595., 54094.,  5454.],
        [  615.,  7243., 54907.]], dtype=torch.float64)
Epoch: 15 | Epoch Time: 46m 49s
	Train Loss: 0.732 | Train Acc: 81.11%
	 Val. Loss: 0.695 |  Val. Acc: 85.61%
tensor([0.8691, 0.7807, 0.8987, 0.8465])
tensor([[55040.,  6745.,  1307.],
        [ 5819., 49782.,  7542.],
        [  800.,  4992., 56973.]], dtype=torch.float64)
Epoch: 16 | Epoch Time: 59m 6s
	Train Loss: 0.733 | Train Acc: 81.06%
	 Val. Loss: 0.706 |  Val. Acc: 84.53%
tensor([0.8155, 0.7835, 0.9150, 0.8356])
tensor([[51627.,  9723.,  1742.],
        [ 3834., 50129.,  9180.],
        [  564.,  4193., 58008.]], dtype=torch.float64)
Epoch: 17 | Epoch Time: 51m 24s
	Train Loss: 0.732 | Train Acc: 81.16%
	 Val. Loss: 0.694 |  Val. Acc: 85.64%
tensor([0.8796, 0.7816, 0.8827, 0.8466])
tensor([[55650.,  6430.,  1012.],
        [ 6379., 50017.,  6747.],
        [ 1025.,  5544., 56196.]], dtype=torch.float64)
Epoch: 18 | Epoch Time: 46m 29s
	Train Loss: 0.731 | Train Acc: 81.31%
	 Val. Loss: 0.695 |  Val. Acc: 85.55%
tensor([0.8862, 0.7421, 0.9177, 0.8446])
tensor([[56061.,  5664.,  1367.],
        [ 6526., 47532.,  9085.],
        [  914.,  3750., 58101.]], dtype=torch.float64)
Epoch: 19 | Epoch Time: 63m 47s
	Train Loss: 0.732 | Train Acc: 81.19%
	 Val. Loss: 0.697 |  Val. Acc: 85.44%
tensor([0.8537, 0.7825, 0.9023, 0.8445])
tensor([[54079.,  7792.,  1221.],
        [ 5191., 50059.,  7893.],
        [  822.,  4608., 57335.]], dtype=torch.float64)
Epoch: 20 | Epoch Time: 45m 45s
	Train Loss: 0.732 | Train Acc: 81.16%
	 Val. Loss: 0.702 |  Val. Acc: 84.92%
tensor([0.9179, 0.6908, 0.9183, 0.8365])
tensor([[58108.,  3674.,  1310.],
        [ 9296., 44240.,  9607.],
        [ 1241.,  3379., 58145.]], dtype=torch.float64)
	 Val. Loss: 0.693 |  Val. Acc: 85.80%
tensor([0.8823, 0.7820, 0.8827, 0.8480])
