nohup: ignoring input
Bert Tokenizer Loaded...
Data loading complete
Number of training examples: 441000
Number of validation examples: 189000
Number of test examples: 270000
defaultdict(None, {'0.0': 0, '1.0': 1, '2.0': 2})
Device in use:  cuda
Epoch: 01 | Epoch Time: 58m 42s
	Train Loss: 4.649 | Train Acc: 67.26%
	 Val. Loss: 4.478 |  Val. Acc: 82.99%
tensor([0.8591, 0.6919, 0.9111, 0.8164])
tensor([[54349.,  6869.,  1874.],
        [ 6756., 44533., 11854.],
        [ 1101.,  3708., 57956.]], dtype=torch.float64)
Epoch: 02 | Epoch Time: 63m 1s
	Train Loss: 4.625 | Train Acc: 70.12%
	 Val. Loss: 4.517 |  Val. Acc: 78.97%
tensor([0.8138, 0.5658, 0.9637, 0.7700])
tensor([[51674.,  6276.,  5142.],
        [ 5213., 36734., 21196.],
        [  513.,  1421., 60831.]], dtype=torch.float64)
Epoch: 03 | Epoch Time: 62m 46s
	Train Loss: 4.621 | Train Acc: 71.06%
	 Val. Loss: 4.466 |  Val. Acc: 84.12%
tensor([0.8417, 0.7710, 0.8833, 0.8307])
tensor([[53271.,  8306.,  1515.],
        [ 5403., 49358.,  8382.],
        [  869.,  5546., 56350.]], dtype=torch.float64)
Epoch: 04 | Epoch Time: 63m 8s
	Train Loss: 4.618 | Train Acc: 71.75%
	 Val. Loss: 4.466 |  Val. Acc: 84.09%
tensor([0.8462, 0.7920, 0.8488, 0.8299])
tensor([[53597.,  8638.,   857.],
        [ 5844., 50724.,  6575.],
        [ 1174.,  6993., 54598.]], dtype=torch.float64)
Epoch: 05 | Epoch Time: 58m 56s
	Train Loss: 4.617 | Train Acc: 71.94%
	 Val. Loss: 4.476 |  Val. Acc: 83.06%
tensor([0.8121, 0.7326, 0.9204, 0.8191])
tensor([[51364.,  9632.,  2096.],
        [ 4428., 47175., 11540.],
        [  665.,  3657., 58443.]], dtype=torch.float64)
Epoch: 06 | Epoch Time: 43m 34s
	Train Loss: 4.615 | Train Acc: 72.08%
	 Val. Loss: 4.465 |  Val. Acc: 84.22%
tensor([0.8992, 0.6985, 0.8984, 0.8288])
tensor([[56933.,  4873.,  1286.],
        [ 8652., 44881.,  9610.],
        [ 1374.,  4034., 57357.]], dtype=torch.float64)
Epoch: 07 | Epoch Time: 36m 17s
	Train Loss: 4.614 | Train Acc: 72.33%
	 Val. Loss: 4.479 |  Val. Acc: 82.76%
tensor([0.9484, 0.6154, 0.8957, 0.8116])
tensor([[59992.,  2183.,   917.],
        [14720., 39378.,  9045.],
        [ 2054.,  3659., 57052.]], dtype=torch.float64)
Epoch: 08 | Epoch Time: 45m 37s
	Train Loss: 4.613 | Train Acc: 72.36%
	 Val. Loss: 4.476 |  Val. Acc: 83.04%
tensor([0.8638, 0.6648, 0.9399, 0.8161])
tensor([[54712.,  5906.,  2474.],
        [ 6331., 42800., 14012.],
        [  789.,  2550., 59426.]], dtype=torch.float64)
Epoch: 09 | Epoch Time: 45m 30s
	Train Loss: 4.613 | Train Acc: 72.80%
	 Val. Loss: 4.458 |  Val. Acc: 84.87%
tensor([0.8888, 0.7571, 0.8671, 0.8371])
tensor([[56292.,  5927.,   873.],
        [ 7500., 48471.,  7172.],
        [ 1295.,  5830., 55640.]], dtype=torch.float64)
Epoch: 10 | Epoch Time: 45m 29s
	Train Loss: 4.613 | Train Acc: 72.79%
	 Val. Loss: 4.471 |  Val. Acc: 83.62%
tensor([0.7845, 0.8324, 0.8590, 0.8266])
tensor([[49719., 12323.,  1050.],
        [ 3518., 53209.,  6416.],
        [  616.,  7040., 55109.]], dtype=torch.float64)
Epoch: 11 | Epoch Time: 45m 22s
	Train Loss: 4.614 | Train Acc: 72.79%
	 Val. Loss: 4.461 |  Val. Acc: 84.56%
tensor([0.8479, 0.7718, 0.8875, 0.8350])
tensor([[53710.,  8086.,  1296.],
        [ 5598., 49451.,  8094.],
        [  982.,  5137., 56646.]], dtype=torch.float64)
Epoch: 12 | Epoch Time: 45m 24s
	Train Loss: 4.613 | Train Acc: 72.75%
	 Val. Loss: 4.465 |  Val. Acc: 84.16%
tensor([0.8759, 0.7033, 0.9191, 0.8287])
tensor([[55477.,  6048.,  1567.],
        [ 6932., 45221., 10990.],
        [  941.,  3467., 58357.]], dtype=torch.float64)
Epoch: 13 | Epoch Time: 45m 21s
	Train Loss: 4.611 | Train Acc: 73.09%
	 Val. Loss: 4.489 |  Val. Acc: 81.78%
tensor([0.8032, 0.6734, 0.9506, 0.8037])
tensor([[50908.,  8845.,  3339.],
        [ 4178., 43513., 15452.],
        [  466.,  2170., 60129.]], dtype=torch.float64)
Epoch: 14 | Epoch Time: 45m 24s
	Train Loss: 4.612 | Train Acc: 73.25%
	 Val. Loss: 4.474 |  Val. Acc: 83.31%
tensor([0.7757, 0.8193, 0.8696, 0.8233])
tensor([[49092., 12795.,  1205.],
        [ 3372., 52558.,  7213.],
        [  592.,  6382., 55791.]], dtype=torch.float64)
Epoch: 15 | Epoch Time: 45m 27s
	Train Loss: 4.611 | Train Acc: 73.23%
	 Val. Loss: 4.458 |  Val. Acc: 84.90%
tensor([0.8886, 0.7355, 0.8946, 0.8372])
tensor([[56196.,  5852.,  1044.],
        [ 7292., 47247.,  8604.],
        [ 1244.,  4510., 57011.]], dtype=torch.float64)
Epoch: 16 | Epoch Time: 45m 25s
	Train Loss: 4.610 | Train Acc: 73.21%
	 Val. Loss: 4.470 |  Val. Acc: 83.71%
tensor([0.8419, 0.7147, 0.9303, 0.8249])
tensor([[53341.,  7835.,  1916.],
        [ 5215., 45926., 12002.],
        [  729.,  3095., 58941.]], dtype=torch.float64)
Epoch: 17 | Epoch Time: 41m 23s
	Train Loss: 4.611 | Train Acc: 73.29%
	 Val. Loss: 4.463 |  Val. Acc: 84.41%
tensor([0.9205, 0.6933, 0.8942, 0.8315])
tensor([[58274.,  3879.,   939.],
        [10249., 44297.,  8597.],
        [ 1612.,  4193., 56960.]], dtype=torch.float64)
Epoch: 18 | Epoch Time: 37m 44s
	Train Loss: 4.609 | Train Acc: 73.74%
	 Val. Loss: 4.474 |  Val. Acc: 83.25%
tensor([0.8020, 0.8710, 0.7862, 0.8220])
tensor([[50903., 11503.,   686.],
        [ 3940., 55448.,  3755.],
        [  779., 10993., 50993.]], dtype=torch.float64)
Epoch: 19 | Epoch Time: 37m 48s
	Train Loss: 4.609 | Train Acc: 73.49%
	 Val. Loss: 4.463 |  Val. Acc: 84.34%
tensor([0.9032, 0.6901, 0.9101, 0.8302])
tensor([[57223.,  4594.,  1275.],
        [ 8856., 44270., 10017.],
        [ 1303.,  3556., 57906.]], dtype=torch.float64)
Epoch: 20 | Epoch Time: 37m 28s
	Train Loss: 4.611 | Train Acc: 73.56%
	 Val. Loss: 4.471 |  Val. Acc: 83.62%
tensor([0.8473, 0.6995, 0.9309, 0.8227])
tensor([[53679.,  7374.,  2039.],
        [ 5459., 45220., 12464.],
        [  694.,  2938., 59133.]], dtype=torch.float64)
	 Val. Loss: 4.457 |  Val. Acc: 85.02%
tensor([0.8919, 0.7351, 0.8941, 0.8382])
